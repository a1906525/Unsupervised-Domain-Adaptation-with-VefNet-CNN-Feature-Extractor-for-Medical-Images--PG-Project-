{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMi6/pLeyNtEQWoLZ6P3gfh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["1. Mount Google Drive in Colab."],"metadata":{"id":"ExL48JgkRv4H"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"SPL5Vur1RwBj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761895906447,"user_tz":-630,"elapsed":25351,"user":{"displayName":"Sai Akshay Suresh","userId":"07578768375236954523"}},"outputId":"4f02ed8b-a498-4c2f-b047-e9e0688dac86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["2) Inspect the Source - Number of Images Per Class, Sizes of Images Per Class, Channels of Images Per Class, and Total Number of Images."],"metadata":{"id":"9ox56U1ZgxP6"}},{"cell_type":"code","source":["import os\n","from PIL import Image\n","from collections import Counter, defaultdict\n","\n","# ── Configuration ──────────────────────────────────────────────────────────\n","src_dir = \"/content/drive/MyDrive/Research Project 2025/Final Data/Preprocessed/Third Set/Source/Step 1 - Moved, Final Source Data\"\n","# ── End configuration ──────────────────────────────────────────────────────\n","\n","def inspect_directory(path):\n","    class_counts = Counter()\n","    class_modes  = defaultdict(Counter)\n","    class_res    = defaultdict(Counter)\n","\n","    for cls in sorted(os.listdir(path)):\n","        cls_path = os.path.join(path, cls)\n","        if not os.path.isdir(cls_path):\n","            continue\n","        for fname in os.listdir(cls_path):\n","            if not fname.lower().endswith(('.png','.jpg','.jpeg','.bmp','.tiff')):\n","                continue\n","            class_counts[cls] += 1\n","            img_path = os.path.join(cls_path, fname)\n","            try:\n","                with Image.open(img_path) as img:\n","                    class_modes[cls][img.mode] += 1\n","                    class_res[cls][img.size] += 1\n","            except Exception as e:\n","                print(f\"❌ Error opening {img_path}: {e}\")\n","\n","    total = sum(class_counts.values())\n","    print(f\"\\nInspection of `{path}`\")\n","    print(f\"{'Class':<12}  Images  Modes               Top Resolutions\")\n","    print(\"-\"*60)\n","    for cls, cnt in class_counts.items():\n","        modes_s = \", \".join(f\"{m}:{n}\" for m,n in class_modes[cls].items())\n","        top3    = class_res[cls].most_common(3)\n","        res_s   = \", \".join(f\"{w}×{h}:{n}\" for (w,h),n in top3)\n","        print(f\"{cls:<12}  {cnt:<6}  {modes_s:<18}  {res_s}\")\n","    print(f\"\\n→ Total images: {total}\\n\")\n","\n","# Run the inspection\n","inspect_directory(src_dir)"],"metadata":{"id":"28pDwNpQgxY4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759720622865,"user_tz":-630,"elapsed":84921,"user":{"displayName":"Sai Akshay Suresh","userId":"07578768375236954523"}},"outputId":"b5cbbb3f-da5f-457f-fb1d-c97b1287cf52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Inspection of `/content/drive/MyDrive/Research Project 2025/Final Data/Preprocessed/Third Set/Source/Step 1 - Moved, Final Source Data`\n","Class         Images  Modes               Top Resolutions\n","------------------------------------------------------------\n","AbdomenCT     500     RGB:500             224×224:500\n","BreastMRI     500     RGB:500             224×224:500\n","ChestCT       500     RGB:500             224×224:500\n","ChestXR       500     RGB:500             224×224:500\n","HandXR        500     RGB:500             224×224:500\n","HeadCT        500     RGB:500             224×224:500\n","\n","→ Total images: 3000\n","\n"]}]},{"cell_type":"markdown","source":["3) Inspect the Target (unlabelled) dataset if it has 3000 images, 224x224 size, and 3 channels."],"metadata":{"id":"4-bSrj8IhL00"}},{"cell_type":"code","source":["import os\n","from PIL import Image\n","from collections import Counter\n","\n","# ── Configuration ──────────────────────────────────────────────────────────\n","unlabelled_dir = \"/content/drive/MyDrive/Research Project 2025/Final Data/Preprocessed/Third Set/Target/Step 2 - Target Unlabelling (Main)/Images\"\n","# ── End configuration ──────────────────────────────────────────────────────\n","\n","# Counters for total, modes, and resolutions\n","total_images = 0\n","mode_counts  = Counter()\n","size_counts  = Counter()\n","\n","# Iterate through all images\n","for fname in os.listdir(unlabelled_dir):\n","    if not fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n","        continue\n","    total_images += 1\n","    img_path = os.path.join(unlabelled_dir, fname)\n","    try:\n","        with Image.open(img_path) as img:\n","            mode_counts[img.mode] += 1\n","            size_counts[img.size] += 1\n","    except Exception as e:\n","        print(f\"❌ Error opening {img_path}: {e}\")\n","\n","# Display results\n","print(f\"\\nInspection of unlabelled target directory: `{unlabelled_dir}`\")\n","print(f\"→ Total images: {total_images}\\n\")\n","\n","print(\"Channel modes:\")\n","for mode, cnt in mode_counts.items():\n","    print(f\"  {mode}: {cnt}\")\n","\n","print(\"\\nImage resolutions:\")\n","for (w, h), cnt in size_counts.most_common():\n","    print(f\"  {w}×{h}: {cnt}\")"],"metadata":{"id":"VKLqvyclhL9e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4) Let us Normalize the source."],"metadata":{"id":"W1QExJbWhQaQ"}},{"cell_type":"code","source":["import os\n","import torch\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from tqdm import tqdm\n","\n","# ── Configuration ────────────────────────────────────────────────────────────\n","data_dir = \"/content/drive/MyDrive/Research Project 2025/Final Data/Preprocessed/Third Set/Source/Step 1 - Moved, Final Source Data\"\n","batch_size = 64   # for batch-level stats\n","num_workers = 4\n","# ── End configuration ─────────────────────────────────────────────────────────\n","\n","# 1) Pre-normalization: load as Tensor [0,1] but no Normalize\n","pre_transform = transforms.Compose([\n","    transforms.ToTensor()   # converts to [C,H,W] in [0.0,1.0]\n","])\n","pre_ds = datasets.ImageFolder(data_dir, transform=pre_transform)\n","pre_loader = DataLoader(pre_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","# Compute channel sums & squared sums\n","n_channels = 3\n","cnt = 0\n","sum_ = torch.zeros(n_channels)\n","sum_sq = torch.zeros(n_channels)\n","\n","for imgs, _ in tqdm(pre_loader, desc=\"Pre-norm stats\"):\n","    # imgs shape: [B, C, H, W]\n","    b, c, h, w = imgs.shape\n","    cnt += b * h * w\n","    sum_ += imgs.sum(dim=[0,2,3])\n","    sum_sq += (imgs ** 2).sum(dim=[0,2,3])\n","\n","mean_pre = sum_ / cnt\n","var_pre = (sum_sq / cnt) - (mean_pre ** 2)\n","std_pre = torch.sqrt(var_pre)\n","\n","print(\"\\nPre-normalization mean:\", mean_pre)\n","print(\"Pre-normalization std: \", std_pre)\n","\n","\n","# 2) One-batch post-normalization: take first batch with Normalize()\n","normalize = transforms.Normalize(mean=mean_pre.tolist(), std=std_pre.tolist())\n","batch_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    normalize\n","])\n","batch_ds = datasets.ImageFolder(data_dir, transform=batch_transform)\n","batch_loader = DataLoader(batch_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","# Get one batch\n","imgs_batch, _ = next(iter(batch_loader))  # [B, C, H, W]\n","mean_batch = imgs_batch.mean(dim=[0,2,3])\n","std_batch  = imgs_batch.std(dim=[0,2,3])\n","\n","print(\"\\nOne-batch post-norm mean:\", mean_batch)\n","print(\"One-batch post-norm std: \", std_batch)\n","\n","\n","# 3) Full-dataset post-normalization: entire loader with Normalize\n","post_loader = DataLoader(batch_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","cnt2 = 0\n","sum2 = torch.zeros(n_channels)\n","sum2_sq = torch.zeros(n_channels)\n","\n","for imgs, _ in tqdm(post_loader, desc=\"Post-norm full stats\"):\n","    b, c, h, w = imgs.shape\n","    cnt2 += b * h * w\n","    sum2 += imgs.sum(dim=[0,2,3])\n","    sum2_sq += (imgs ** 2).sum(dim=[0,2,3])\n","\n","mean_post = sum2 / cnt2\n","var_post = (sum2_sq / cnt2) - (mean_post ** 2)\n","std_post = torch.sqrt(var_post)\n","\n","print(\"\\nPost-normalization mean:\", mean_post)\n","print(\"Post-normalization std: \", std_post)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dNi3zJmhhQlq","executionInfo":{"status":"ok","timestamp":1759720676838,"user_tz":-630,"elapsed":53960,"user":{"displayName":"Sai Akshay Suresh","userId":"07578768375236954523"}},"outputId":"de4c038a-d638-410d-d062-1ee9d5382d87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Pre-norm stats: 100%|██████████| 47/47 [00:19<00:00,  2.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Pre-normalization mean: tensor([0.2800, 0.2800, 0.2800])\n","Pre-normalization std:  tensor([0.3013, 0.3013, 0.3013])\n","\n","One-batch post-norm mean: tensor([0.1287, 0.1287, 0.1287])\n","One-batch post-norm std:  tensor([0.6009, 0.6009, 0.6009])\n"]},{"output_type":"stream","name":"stderr","text":["Post-norm full stats: 100%|██████████| 47/47 [00:18<00:00,  2.59it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Post-normalization mean: tensor([8.7193e-08, 8.7193e-08, 8.7193e-08])\n","Post-normalization std:  tensor([1.0000, 1.0000, 1.0000])\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["5) Let us build the ResNet-50 architecture.\n","Inspired from : https://arxiv.org/abs/1512.03385"],"metadata":{"id":"8GZuwuA_hXp1"}},{"cell_type":"code","source":["# ResNet-50 (2015, v1) using PyTorch + summary (Keras-like)\n","# Matches the original paper’s bottleneck: [1x1, 3x3, 1x1], expansion=4\n","# Downsampling rule (v1): stride=2 in the FIRST 1x1 conv of a stage that downsamples.\n","# Projection shortcut (option B) via 1x1 conv when shape changes.\n","# forward_features() returns a 2048-d vector (handy for DA heads like DANN/ADDA).\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# ---- Bottleneck block (ResNet v1) ----\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super().__init__()\n","        # v1: put stride on the FIRST 1x1 conv when downsampling\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n","        self.bn1   = nn.BatchNorm2d(planes)\n","\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2   = nn.BatchNorm2d(planes)\n","\n","        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n","        self.bn3   = nn.BatchNorm2d(planes * self.expansion)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x); out = self.bn1(out); out = self.relu(out)\n","        out = self.conv2(out); out = self.bn2(out); out = self.relu(out)\n","        out = self.conv3(out); out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","        return out\n","\n","# ---- ResNet-50 (v1) ----\n","class ResNet50V1(nn.Module):\n","    \"\"\"\n","    ResNet-50 (He et al., 2015)\n","      Stem: 7x7 conv, 64, s=2 -> 3x3 maxpool, s=2\n","      Stages (Bottleneck blocks): [3, 4, 6, 3] with planes [64, 128, 256, 512]\n","      Downsample at the START of stages 2,3,4 via stride=2 in the first 1x1 conv (v1 rule).\n","      Head: global avg pool -> FC(num_classes)\n","    \"\"\"\n","    def __init__(self, num_classes=6):\n","        super().__init__()\n","        self.inplanes = 64\n","\n","        # Stem\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1   = nn.BatchNorm2d(64)\n","        self.relu  = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        # Stages\n","        self.layer1 = self._make_layer(Bottleneck, planes=64,  blocks=3, stride=1)  # 56x56\n","        self.layer2 = self._make_layer(Bottleneck, planes=128, blocks=4, stride=2)  # 28x28\n","        self.layer3 = self._make_layer(Bottleneck, planes=256, blocks=6, stride=2)  # 14x14\n","        self.layer4 = self._make_layer(Bottleneck, planes=512, blocks=3, stride=2)  # 7x7\n","\n","        # Head\n","        self.avgpool   = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc        = nn.Linear(512 * Bottleneck.expansion, num_classes)\n","\n","        self._init_weights()\n","\n","    def _make_layer(self, block, planes, blocks, stride):\n","        \"\"\"Create one ResNet stage.\"\"\"\n","        downsample = None\n","        outplanes = planes * block.expansion\n","\n","        # If shape changes (either spatial via stride>1 or channel via expansion), use projection shortcut.\n","        if stride != 1 or self.inplanes != outplanes:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, outplanes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(outplanes),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride=stride, downsample=downsample))\n","        self.inplanes = outplanes\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, stride=1, downsample=None))\n","        return nn.Sequential(*layers)\n","\n","    def _init_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.ones_(m.weight); nn.init.zeros_(m.bias)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01); nn.init.zeros_(m.bias)\n","\n","    # Handy for DA heads\n","    def forward_features(self, x):\n","        x = self.conv1(x); x = self.bn1(x); x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        return torch.flatten(x, 1)  # 2048-d\n","\n","    def forward(self, x):\n","        x = self.forward_features(x)\n","        x = self.fc(x)\n","        return x\n","\n","# --- Smoke test + Summary ---\n","if __name__ == \"__main__\":\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    m = ResNet50V1(num_classes=6).to(device)\n","\n","    # try to import torchinfo; auto-install if missing (Colab-friendly)\n","    try:\n","        from torchinfo import summary\n","    except Exception as e:\n","        import sys, subprocess\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torchinfo\"])\n","        from torchinfo import summary\n","\n","    # Print Keras-like summary (expand bottleneck internals)\n","    print(summary(\n","        m,\n","        input_size=(1, 3, 224, 224),\n","        device=device,\n","        col_names=(\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"),\n","        depth=3,\n","        verbose=1\n","    ))\n","\n","    # Quick forward check + param count\n","    x = torch.randn(2, 3, 224, 224, device=device)\n","    y = m(x)\n","    total = sum(p.numel() for p in m.parameters())\n","    trainable = sum(p.numel() for p in m.parameters() if p.requires_grad)\n","    print(\"Output shape:\", y.shape)  # expect: torch.Size([2, 6])\n","    print(f\"Total params: {total:,} | Trainable: {trainable:,}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUvE8n1yhXxi","executionInfo":{"status":"ok","timestamp":1761895940080,"user_tz":-630,"elapsed":8296,"user":{"displayName":"Sai Akshay Suresh","userId":"07578768375236954523"}},"outputId":"b1bbb8ab-41e6-4c41-88ca-97db4d704dc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================================================================================================\n","Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape\n","============================================================================================================================================\n","ResNet50V1                               [1, 3, 224, 224]          [1, 6]                    --                        --\n","├─Conv2d: 1-1                            [1, 3, 224, 224]          [1, 64, 112, 112]         9,408                     [7, 7]\n","├─BatchNorm2d: 1-2                       [1, 64, 112, 112]         [1, 64, 112, 112]         128                       --\n","├─ReLU: 1-3                              [1, 64, 112, 112]         [1, 64, 112, 112]         --                        --\n","├─MaxPool2d: 1-4                         [1, 64, 112, 112]         [1, 64, 56, 56]           --                        3\n","├─Sequential: 1-5                        [1, 64, 56, 56]           [1, 256, 56, 56]          --                        --\n","│    └─Bottleneck: 2-1                   [1, 64, 56, 56]           [1, 256, 56, 56]          --                        --\n","│    │    └─Conv2d: 3-1                  [1, 64, 56, 56]           [1, 64, 56, 56]           4,096                     [1, 1]\n","│    │    └─BatchNorm2d: 3-2             [1, 64, 56, 56]           [1, 64, 56, 56]           128                       --\n","│    │    └─ReLU: 3-3                    [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n","│    │    └─Conv2d: 3-4                  [1, 64, 56, 56]           [1, 64, 56, 56]           36,864                    [3, 3]\n","│    │    └─BatchNorm2d: 3-5             [1, 64, 56, 56]           [1, 64, 56, 56]           128                       --\n","│    │    └─ReLU: 3-6                    [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n","│    │    └─Conv2d: 3-7                  [1, 64, 56, 56]           [1, 256, 56, 56]          16,384                    [1, 1]\n","│    │    └─BatchNorm2d: 3-8             [1, 256, 56, 56]          [1, 256, 56, 56]          512                       --\n","│    │    └─Sequential: 3-9              [1, 64, 56, 56]           [1, 256, 56, 56]          16,896                    --\n","│    │    └─ReLU: 3-10                   [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --\n","│    └─Bottleneck: 2-2                   [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --\n","│    │    └─Conv2d: 3-11                 [1, 256, 56, 56]          [1, 64, 56, 56]           16,384                    [1, 1]\n","│    │    └─BatchNorm2d: 3-12            [1, 64, 56, 56]           [1, 64, 56, 56]           128                       --\n","│    │    └─ReLU: 3-13                   [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n","│    │    └─Conv2d: 3-14                 [1, 64, 56, 56]           [1, 64, 56, 56]           36,864                    [3, 3]\n","│    │    └─BatchNorm2d: 3-15            [1, 64, 56, 56]           [1, 64, 56, 56]           128                       --\n","│    │    └─ReLU: 3-16                   [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n","│    │    └─Conv2d: 3-17                 [1, 64, 56, 56]           [1, 256, 56, 56]          16,384                    [1, 1]\n","│    │    └─BatchNorm2d: 3-18            [1, 256, 56, 56]          [1, 256, 56, 56]          512                       --\n","│    │    └─ReLU: 3-19                   [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --\n","│    └─Bottleneck: 2-3                   [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --\n","│    │    └─Conv2d: 3-20                 [1, 256, 56, 56]          [1, 64, 56, 56]           16,384                    [1, 1]\n","│    │    └─BatchNorm2d: 3-21            [1, 64, 56, 56]           [1, 64, 56, 56]           128                       --\n","│    │    └─ReLU: 3-22                   [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n","│    │    └─Conv2d: 3-23                 [1, 64, 56, 56]           [1, 64, 56, 56]           36,864                    [3, 3]\n","│    │    └─BatchNorm2d: 3-24            [1, 64, 56, 56]           [1, 64, 56, 56]           128                       --\n","│    │    └─ReLU: 3-25                   [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n","│    │    └─Conv2d: 3-26                 [1, 64, 56, 56]           [1, 256, 56, 56]          16,384                    [1, 1]\n","│    │    └─BatchNorm2d: 3-27            [1, 256, 56, 56]          [1, 256, 56, 56]          512                       --\n","│    │    └─ReLU: 3-28                   [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --\n","├─Sequential: 1-6                        [1, 256, 56, 56]          [1, 512, 28, 28]          --                        --\n","│    └─Bottleneck: 2-4                   [1, 256, 56, 56]          [1, 512, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-29                 [1, 256, 56, 56]          [1, 128, 28, 28]          32,768                    [1, 1]\n","│    │    └─BatchNorm2d: 3-30            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-31                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-32                 [1, 128, 28, 28]          [1, 128, 28, 28]          147,456                   [3, 3]\n","│    │    └─BatchNorm2d: 3-33            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-34                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-35                 [1, 128, 28, 28]          [1, 512, 28, 28]          65,536                    [1, 1]\n","│    │    └─BatchNorm2d: 3-36            [1, 512, 28, 28]          [1, 512, 28, 28]          1,024                     --\n","│    │    └─Sequential: 3-37             [1, 256, 56, 56]          [1, 512, 28, 28]          132,096                   --\n","│    │    └─ReLU: 3-38                   [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --\n","│    └─Bottleneck: 2-5                   [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-39                 [1, 512, 28, 28]          [1, 128, 28, 28]          65,536                    [1, 1]\n","│    │    └─BatchNorm2d: 3-40            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-41                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-42                 [1, 128, 28, 28]          [1, 128, 28, 28]          147,456                   [3, 3]\n","│    │    └─BatchNorm2d: 3-43            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-44                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-45                 [1, 128, 28, 28]          [1, 512, 28, 28]          65,536                    [1, 1]\n","│    │    └─BatchNorm2d: 3-46            [1, 512, 28, 28]          [1, 512, 28, 28]          1,024                     --\n","│    │    └─ReLU: 3-47                   [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --\n","│    └─Bottleneck: 2-6                   [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-48                 [1, 512, 28, 28]          [1, 128, 28, 28]          65,536                    [1, 1]\n","│    │    └─BatchNorm2d: 3-49            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-50                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-51                 [1, 128, 28, 28]          [1, 128, 28, 28]          147,456                   [3, 3]\n","│    │    └─BatchNorm2d: 3-52            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-53                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-54                 [1, 128, 28, 28]          [1, 512, 28, 28]          65,536                    [1, 1]\n","│    │    └─BatchNorm2d: 3-55            [1, 512, 28, 28]          [1, 512, 28, 28]          1,024                     --\n","│    │    └─ReLU: 3-56                   [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --\n","│    └─Bottleneck: 2-7                   [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-57                 [1, 512, 28, 28]          [1, 128, 28, 28]          65,536                    [1, 1]\n","│    │    └─BatchNorm2d: 3-58            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-59                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-60                 [1, 128, 28, 28]          [1, 128, 28, 28]          147,456                   [3, 3]\n","│    │    └─BatchNorm2d: 3-61            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-62                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-63                 [1, 128, 28, 28]          [1, 512, 28, 28]          65,536                    [1, 1]\n","│    │    └─BatchNorm2d: 3-64            [1, 512, 28, 28]          [1, 512, 28, 28]          1,024                     --\n","│    │    └─ReLU: 3-65                   [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --\n","├─Sequential: 1-7                        [1, 512, 28, 28]          [1, 1024, 14, 14]         --                        --\n","│    └─Bottleneck: 2-8                   [1, 512, 28, 28]          [1, 1024, 14, 14]         --                        --\n","│    │    └─Conv2d: 3-66                 [1, 512, 28, 28]          [1, 256, 14, 14]          131,072                   [1, 1]\n","│    │    └─BatchNorm2d: 3-67            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-68                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-69                 [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   [3, 3]\n","│    │    └─BatchNorm2d: 3-70            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-71                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-72                 [1, 256, 14, 14]          [1, 1024, 14, 14]         262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-73            [1, 1024, 14, 14]         [1, 1024, 14, 14]         2,048                     --\n","│    │    └─Sequential: 3-74             [1, 512, 28, 28]          [1, 1024, 14, 14]         526,336                   --\n","│    │    └─ReLU: 3-75                   [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    └─Bottleneck: 2-9                   [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    │    └─Conv2d: 3-76                 [1, 1024, 14, 14]         [1, 256, 14, 14]          262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-77            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-78                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-79                 [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   [3, 3]\n","│    │    └─BatchNorm2d: 3-80            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-81                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-82                 [1, 256, 14, 14]          [1, 1024, 14, 14]         262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-83            [1, 1024, 14, 14]         [1, 1024, 14, 14]         2,048                     --\n","│    │    └─ReLU: 3-84                   [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    └─Bottleneck: 2-10                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    │    └─Conv2d: 3-85                 [1, 1024, 14, 14]         [1, 256, 14, 14]          262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-86            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-87                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-88                 [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   [3, 3]\n","│    │    └─BatchNorm2d: 3-89            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-90                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-91                 [1, 256, 14, 14]          [1, 1024, 14, 14]         262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-92            [1, 1024, 14, 14]         [1, 1024, 14, 14]         2,048                     --\n","│    │    └─ReLU: 3-93                   [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    └─Bottleneck: 2-11                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    │    └─Conv2d: 3-94                 [1, 1024, 14, 14]         [1, 256, 14, 14]          262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-95            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-96                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-97                 [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   [3, 3]\n","│    │    └─BatchNorm2d: 3-98            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-99                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-100                [1, 256, 14, 14]          [1, 1024, 14, 14]         262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-101           [1, 1024, 14, 14]         [1, 1024, 14, 14]         2,048                     --\n","│    │    └─ReLU: 3-102                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    └─Bottleneck: 2-12                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    │    └─Conv2d: 3-103                [1, 1024, 14, 14]         [1, 256, 14, 14]          262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-104           [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-105                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-106                [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   [3, 3]\n","│    │    └─BatchNorm2d: 3-107           [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-108                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-109                [1, 256, 14, 14]          [1, 1024, 14, 14]         262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-110           [1, 1024, 14, 14]         [1, 1024, 14, 14]         2,048                     --\n","│    │    └─ReLU: 3-111                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    └─Bottleneck: 2-13                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    │    └─Conv2d: 3-112                [1, 1024, 14, 14]         [1, 256, 14, 14]          262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-113           [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-114                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-115                [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   [3, 3]\n","│    │    └─BatchNorm2d: 3-116           [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-117                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-118                [1, 256, 14, 14]          [1, 1024, 14, 14]         262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-119           [1, 1024, 14, 14]         [1, 1024, 14, 14]         2,048                     --\n","│    │    └─ReLU: 3-120                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","├─Sequential: 1-8                        [1, 1024, 14, 14]         [1, 2048, 7, 7]           --                        --\n","│    └─Bottleneck: 2-14                  [1, 1024, 14, 14]         [1, 2048, 7, 7]           --                        --\n","│    │    └─Conv2d: 3-121                [1, 1024, 14, 14]         [1, 512, 7, 7]            524,288                   [1, 1]\n","│    │    └─BatchNorm2d: 3-122           [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     --\n","│    │    └─ReLU: 3-123                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n","│    │    └─Conv2d: 3-124                [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296                 [3, 3]\n","│    │    └─BatchNorm2d: 3-125           [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     --\n","│    │    └─ReLU: 3-126                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n","│    │    └─Conv2d: 3-127                [1, 512, 7, 7]            [1, 2048, 7, 7]           1,048,576                 [1, 1]\n","│    │    └─BatchNorm2d: 3-128           [1, 2048, 7, 7]           [1, 2048, 7, 7]           4,096                     --\n","│    │    └─Sequential: 3-129            [1, 1024, 14, 14]         [1, 2048, 7, 7]           2,101,248                 --\n","│    │    └─ReLU: 3-130                  [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --\n","│    └─Bottleneck: 2-15                  [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --\n","│    │    └─Conv2d: 3-131                [1, 2048, 7, 7]           [1, 512, 7, 7]            1,048,576                 [1, 1]\n","│    │    └─BatchNorm2d: 3-132           [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     --\n","│    │    └─ReLU: 3-133                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n","│    │    └─Conv2d: 3-134                [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296                 [3, 3]\n","│    │    └─BatchNorm2d: 3-135           [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     --\n","│    │    └─ReLU: 3-136                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n","│    │    └─Conv2d: 3-137                [1, 512, 7, 7]            [1, 2048, 7, 7]           1,048,576                 [1, 1]\n","│    │    └─BatchNorm2d: 3-138           [1, 2048, 7, 7]           [1, 2048, 7, 7]           4,096                     --\n","│    │    └─ReLU: 3-139                  [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --\n","│    └─Bottleneck: 2-16                  [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --\n","│    │    └─Conv2d: 3-140                [1, 2048, 7, 7]           [1, 512, 7, 7]            1,048,576                 [1, 1]\n","│    │    └─BatchNorm2d: 3-141           [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     --\n","│    │    └─ReLU: 3-142                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n","│    │    └─Conv2d: 3-143                [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296                 [3, 3]\n","│    │    └─BatchNorm2d: 3-144           [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     --\n","│    │    └─ReLU: 3-145                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n","│    │    └─Conv2d: 3-146                [1, 512, 7, 7]            [1, 2048, 7, 7]           1,048,576                 [1, 1]\n","│    │    └─BatchNorm2d: 3-147           [1, 2048, 7, 7]           [1, 2048, 7, 7]           4,096                     --\n","│    │    └─ReLU: 3-148                  [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --\n","├─AdaptiveAvgPool2d: 1-9                 [1, 2048, 7, 7]           [1, 2048, 1, 1]           --                        --\n","├─Linear: 1-10                           [1, 2048]                 [1, 6]                    12,294                    --\n","============================================================================================================================================\n","Total params: 23,520,326\n","Trainable params: 23,520,326\n","Non-trainable params: 0\n","Total mult-adds (Units.GIGABYTES): 3.86\n","============================================================================================================================================\n","Input size (MB): 0.60\n","Forward/backward pass size (MB): 169.39\n","Params size (MB): 94.08\n","Estimated Total Size (MB): 264.08\n","============================================================================================================================================\n","============================================================================================================================================\n","Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape\n","============================================================================================================================================\n","ResNet50V1                               [1, 3, 224, 224]          [1, 6]                    --                        --\n","├─Conv2d: 1-1                            [1, 3, 224, 224]          [1, 64, 112, 112]         9,408                     [7, 7]\n","├─BatchNorm2d: 1-2                       [1, 64, 112, 112]         [1, 64, 112, 112]         128                       --\n","├─ReLU: 1-3                              [1, 64, 112, 112]         [1, 64, 112, 112]         --                        --\n","├─MaxPool2d: 1-4                         [1, 64, 112, 112]         [1, 64, 56, 56]           --                        3\n","├─Sequential: 1-5                        [1, 64, 56, 56]           [1, 256, 56, 56]          --                        --\n","│    └─Bottleneck: 2-1                   [1, 64, 56, 56]           [1, 256, 56, 56]          --                        --\n","│    │    └─Conv2d: 3-1                  [1, 64, 56, 56]           [1, 64, 56, 56]           4,096                     [1, 1]\n","│    │    └─BatchNorm2d: 3-2             [1, 64, 56, 56]           [1, 64, 56, 56]           128                       --\n","│    │    └─ReLU: 3-3                    [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n","│    │    └─Conv2d: 3-4                  [1, 64, 56, 56]           [1, 64, 56, 56]           36,864                    [3, 3]\n","│    │    └─BatchNorm2d: 3-5             [1, 64, 56, 56]           [1, 64, 56, 56]           128                       --\n","│    │    └─ReLU: 3-6                    [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n","│    │    └─Conv2d: 3-7                  [1, 64, 56, 56]           [1, 256, 56, 56]          16,384                    [1, 1]\n","│    │    └─BatchNorm2d: 3-8             [1, 256, 56, 56]          [1, 256, 56, 56]          512                       --\n","│    │    └─Sequential: 3-9              [1, 64, 56, 56]           [1, 256, 56, 56]          16,896                    --\n","│    │    └─ReLU: 3-10                   [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --\n","│    └─Bottleneck: 2-2                   [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --\n","│    │    └─Conv2d: 3-11                 [1, 256, 56, 56]          [1, 64, 56, 56]           16,384                    [1, 1]\n","│    │    └─BatchNorm2d: 3-12            [1, 64, 56, 56]           [1, 64, 56, 56]           128                       --\n","│    │    └─ReLU: 3-13                   [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n","│    │    └─Conv2d: 3-14                 [1, 64, 56, 56]           [1, 64, 56, 56]           36,864                    [3, 3]\n","│    │    └─BatchNorm2d: 3-15            [1, 64, 56, 56]           [1, 64, 56, 56]           128                       --\n","│    │    └─ReLU: 3-16                   [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n","│    │    └─Conv2d: 3-17                 [1, 64, 56, 56]           [1, 256, 56, 56]          16,384                    [1, 1]\n","│    │    └─BatchNorm2d: 3-18            [1, 256, 56, 56]          [1, 256, 56, 56]          512                       --\n","│    │    └─ReLU: 3-19                   [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --\n","│    └─Bottleneck: 2-3                   [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --\n","│    │    └─Conv2d: 3-20                 [1, 256, 56, 56]          [1, 64, 56, 56]           16,384                    [1, 1]\n","│    │    └─BatchNorm2d: 3-21            [1, 64, 56, 56]           [1, 64, 56, 56]           128                       --\n","│    │    └─ReLU: 3-22                   [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n","│    │    └─Conv2d: 3-23                 [1, 64, 56, 56]           [1, 64, 56, 56]           36,864                    [3, 3]\n","│    │    └─BatchNorm2d: 3-24            [1, 64, 56, 56]           [1, 64, 56, 56]           128                       --\n","│    │    └─ReLU: 3-25                   [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n","│    │    └─Conv2d: 3-26                 [1, 64, 56, 56]           [1, 256, 56, 56]          16,384                    [1, 1]\n","│    │    └─BatchNorm2d: 3-27            [1, 256, 56, 56]          [1, 256, 56, 56]          512                       --\n","│    │    └─ReLU: 3-28                   [1, 256, 56, 56]          [1, 256, 56, 56]          --                        --\n","├─Sequential: 1-6                        [1, 256, 56, 56]          [1, 512, 28, 28]          --                        --\n","│    └─Bottleneck: 2-4                   [1, 256, 56, 56]          [1, 512, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-29                 [1, 256, 56, 56]          [1, 128, 28, 28]          32,768                    [1, 1]\n","│    │    └─BatchNorm2d: 3-30            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-31                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-32                 [1, 128, 28, 28]          [1, 128, 28, 28]          147,456                   [3, 3]\n","│    │    └─BatchNorm2d: 3-33            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-34                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-35                 [1, 128, 28, 28]          [1, 512, 28, 28]          65,536                    [1, 1]\n","│    │    └─BatchNorm2d: 3-36            [1, 512, 28, 28]          [1, 512, 28, 28]          1,024                     --\n","│    │    └─Sequential: 3-37             [1, 256, 56, 56]          [1, 512, 28, 28]          132,096                   --\n","│    │    └─ReLU: 3-38                   [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --\n","│    └─Bottleneck: 2-5                   [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-39                 [1, 512, 28, 28]          [1, 128, 28, 28]          65,536                    [1, 1]\n","│    │    └─BatchNorm2d: 3-40            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-41                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-42                 [1, 128, 28, 28]          [1, 128, 28, 28]          147,456                   [3, 3]\n","│    │    └─BatchNorm2d: 3-43            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-44                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-45                 [1, 128, 28, 28]          [1, 512, 28, 28]          65,536                    [1, 1]\n","│    │    └─BatchNorm2d: 3-46            [1, 512, 28, 28]          [1, 512, 28, 28]          1,024                     --\n","│    │    └─ReLU: 3-47                   [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --\n","│    └─Bottleneck: 2-6                   [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-48                 [1, 512, 28, 28]          [1, 128, 28, 28]          65,536                    [1, 1]\n","│    │    └─BatchNorm2d: 3-49            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-50                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-51                 [1, 128, 28, 28]          [1, 128, 28, 28]          147,456                   [3, 3]\n","│    │    └─BatchNorm2d: 3-52            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-53                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-54                 [1, 128, 28, 28]          [1, 512, 28, 28]          65,536                    [1, 1]\n","│    │    └─BatchNorm2d: 3-55            [1, 512, 28, 28]          [1, 512, 28, 28]          1,024                     --\n","│    │    └─ReLU: 3-56                   [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --\n","│    └─Bottleneck: 2-7                   [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-57                 [1, 512, 28, 28]          [1, 128, 28, 28]          65,536                    [1, 1]\n","│    │    └─BatchNorm2d: 3-58            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-59                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-60                 [1, 128, 28, 28]          [1, 128, 28, 28]          147,456                   [3, 3]\n","│    │    └─BatchNorm2d: 3-61            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       --\n","│    │    └─ReLU: 3-62                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n","│    │    └─Conv2d: 3-63                 [1, 128, 28, 28]          [1, 512, 28, 28]          65,536                    [1, 1]\n","│    │    └─BatchNorm2d: 3-64            [1, 512, 28, 28]          [1, 512, 28, 28]          1,024                     --\n","│    │    └─ReLU: 3-65                   [1, 512, 28, 28]          [1, 512, 28, 28]          --                        --\n","├─Sequential: 1-7                        [1, 512, 28, 28]          [1, 1024, 14, 14]         --                        --\n","│    └─Bottleneck: 2-8                   [1, 512, 28, 28]          [1, 1024, 14, 14]         --                        --\n","│    │    └─Conv2d: 3-66                 [1, 512, 28, 28]          [1, 256, 14, 14]          131,072                   [1, 1]\n","│    │    └─BatchNorm2d: 3-67            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-68                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-69                 [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   [3, 3]\n","│    │    └─BatchNorm2d: 3-70            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-71                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-72                 [1, 256, 14, 14]          [1, 1024, 14, 14]         262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-73            [1, 1024, 14, 14]         [1, 1024, 14, 14]         2,048                     --\n","│    │    └─Sequential: 3-74             [1, 512, 28, 28]          [1, 1024, 14, 14]         526,336                   --\n","│    │    └─ReLU: 3-75                   [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    └─Bottleneck: 2-9                   [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    │    └─Conv2d: 3-76                 [1, 1024, 14, 14]         [1, 256, 14, 14]          262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-77            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-78                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-79                 [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   [3, 3]\n","│    │    └─BatchNorm2d: 3-80            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-81                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-82                 [1, 256, 14, 14]          [1, 1024, 14, 14]         262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-83            [1, 1024, 14, 14]         [1, 1024, 14, 14]         2,048                     --\n","│    │    └─ReLU: 3-84                   [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    └─Bottleneck: 2-10                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    │    └─Conv2d: 3-85                 [1, 1024, 14, 14]         [1, 256, 14, 14]          262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-86            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-87                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-88                 [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   [3, 3]\n","│    │    └─BatchNorm2d: 3-89            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-90                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-91                 [1, 256, 14, 14]          [1, 1024, 14, 14]         262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-92            [1, 1024, 14, 14]         [1, 1024, 14, 14]         2,048                     --\n","│    │    └─ReLU: 3-93                   [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    └─Bottleneck: 2-11                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    │    └─Conv2d: 3-94                 [1, 1024, 14, 14]         [1, 256, 14, 14]          262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-95            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-96                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-97                 [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   [3, 3]\n","│    │    └─BatchNorm2d: 3-98            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-99                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-100                [1, 256, 14, 14]          [1, 1024, 14, 14]         262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-101           [1, 1024, 14, 14]         [1, 1024, 14, 14]         2,048                     --\n","│    │    └─ReLU: 3-102                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    └─Bottleneck: 2-12                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    │    └─Conv2d: 3-103                [1, 1024, 14, 14]         [1, 256, 14, 14]          262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-104           [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-105                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-106                [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   [3, 3]\n","│    │    └─BatchNorm2d: 3-107           [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-108                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-109                [1, 256, 14, 14]          [1, 1024, 14, 14]         262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-110           [1, 1024, 14, 14]         [1, 1024, 14, 14]         2,048                     --\n","│    │    └─ReLU: 3-111                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    └─Bottleneck: 2-13                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","│    │    └─Conv2d: 3-112                [1, 1024, 14, 14]         [1, 256, 14, 14]          262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-113           [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-114                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-115                [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   [3, 3]\n","│    │    └─BatchNorm2d: 3-116           [1, 256, 14, 14]          [1, 256, 14, 14]          512                       --\n","│    │    └─ReLU: 3-117                  [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n","│    │    └─Conv2d: 3-118                [1, 256, 14, 14]          [1, 1024, 14, 14]         262,144                   [1, 1]\n","│    │    └─BatchNorm2d: 3-119           [1, 1024, 14, 14]         [1, 1024, 14, 14]         2,048                     --\n","│    │    └─ReLU: 3-120                  [1, 1024, 14, 14]         [1, 1024, 14, 14]         --                        --\n","├─Sequential: 1-8                        [1, 1024, 14, 14]         [1, 2048, 7, 7]           --                        --\n","│    └─Bottleneck: 2-14                  [1, 1024, 14, 14]         [1, 2048, 7, 7]           --                        --\n","│    │    └─Conv2d: 3-121                [1, 1024, 14, 14]         [1, 512, 7, 7]            524,288                   [1, 1]\n","│    │    └─BatchNorm2d: 3-122           [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     --\n","│    │    └─ReLU: 3-123                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n","│    │    └─Conv2d: 3-124                [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296                 [3, 3]\n","│    │    └─BatchNorm2d: 3-125           [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     --\n","│    │    └─ReLU: 3-126                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n","│    │    └─Conv2d: 3-127                [1, 512, 7, 7]            [1, 2048, 7, 7]           1,048,576                 [1, 1]\n","│    │    └─BatchNorm2d: 3-128           [1, 2048, 7, 7]           [1, 2048, 7, 7]           4,096                     --\n","│    │    └─Sequential: 3-129            [1, 1024, 14, 14]         [1, 2048, 7, 7]           2,101,248                 --\n","│    │    └─ReLU: 3-130                  [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --\n","│    └─Bottleneck: 2-15                  [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --\n","│    │    └─Conv2d: 3-131                [1, 2048, 7, 7]           [1, 512, 7, 7]            1,048,576                 [1, 1]\n","│    │    └─BatchNorm2d: 3-132           [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     --\n","│    │    └─ReLU: 3-133                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n","│    │    └─Conv2d: 3-134                [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296                 [3, 3]\n","│    │    └─BatchNorm2d: 3-135           [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     --\n","│    │    └─ReLU: 3-136                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n","│    │    └─Conv2d: 3-137                [1, 512, 7, 7]            [1, 2048, 7, 7]           1,048,576                 [1, 1]\n","│    │    └─BatchNorm2d: 3-138           [1, 2048, 7, 7]           [1, 2048, 7, 7]           4,096                     --\n","│    │    └─ReLU: 3-139                  [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --\n","│    └─Bottleneck: 2-16                  [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --\n","│    │    └─Conv2d: 3-140                [1, 2048, 7, 7]           [1, 512, 7, 7]            1,048,576                 [1, 1]\n","│    │    └─BatchNorm2d: 3-141           [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     --\n","│    │    └─ReLU: 3-142                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n","│    │    └─Conv2d: 3-143                [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296                 [3, 3]\n","│    │    └─BatchNorm2d: 3-144           [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     --\n","│    │    └─ReLU: 3-145                  [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n","│    │    └─Conv2d: 3-146                [1, 512, 7, 7]            [1, 2048, 7, 7]           1,048,576                 [1, 1]\n","│    │    └─BatchNorm2d: 3-147           [1, 2048, 7, 7]           [1, 2048, 7, 7]           4,096                     --\n","│    │    └─ReLU: 3-148                  [1, 2048, 7, 7]           [1, 2048, 7, 7]           --                        --\n","├─AdaptiveAvgPool2d: 1-9                 [1, 2048, 7, 7]           [1, 2048, 1, 1]           --                        --\n","├─Linear: 1-10                           [1, 2048]                 [1, 6]                    12,294                    --\n","============================================================================================================================================\n","Total params: 23,520,326\n","Trainable params: 23,520,326\n","Non-trainable params: 0\n","Total mult-adds (Units.GIGABYTES): 3.86\n","============================================================================================================================================\n","Input size (MB): 0.60\n","Forward/backward pass size (MB): 169.39\n","Params size (MB): 94.08\n","Estimated Total Size (MB): 264.08\n","============================================================================================================================================\n","Output shape: torch.Size([2, 6])\n","Total params: 23,520,326 | Trainable: 23,520,326\n"]}]},{"cell_type":"markdown","source":["6) Let us prepare the data loaders for split."],"metadata":{"id":"CD7HC0ETiM7l"}},{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os, torch\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader, Subset\n","\n","# Paths\n","source_dir = '/content/drive/MyDrive/Research Project 2025/Final Data/Preprocessed/Third Set/Source/Step 1 - Moved, Final Source Data'\n","\n","# Precomputed normalization stats\n","mean = [0.2800, 0.2800, 0.2800]\n","std  = [0.3013, 0.3013, 0.3013]\n","\n","# Transforms\n","train_transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(8),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std),\n","])\n","val_test_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std),\n","])\n","\n","# 1) Load a base dataset (no transform) just to get length/labels\n","base_ds = ImageFolder(source_dir, transform=None)\n","\n","# 2) Deterministic split indices (NOT random_split on a list)\n","torch.manual_seed(1906525)\n","n_total = len(base_ds)\n","n_train = int(0.75 * n_total)\n","n_val   = int(0.10 * n_total)\n","n_test  = n_total - n_train - n_val\n","\n","perm = torch.randperm(n_total)\n","train_idx = perm[:n_train]\n","val_idx   = perm[n_train:n_train+n_val]\n","test_idx  = perm[n_train+n_val:]\n","\n","# 3) Make three datasets with their own transforms, then subset by the same indices\n","train_full = ImageFolder(source_dir, transform=train_transform)\n","val_full   = ImageFolder(source_dir, transform=val_test_transform)\n","test_full  = ImageFolder(source_dir, transform=val_test_transform)\n","\n","train_ds = Subset(train_full, train_idx)\n","val_ds   = Subset(val_full,   val_idx)\n","test_ds  = Subset(test_full,  test_idx)\n","\n","# 4) DataLoaders (Drive I/O tips: pin_memory + persistent_workers)\n","batch_size, num_workers = 32, 4\n","loader_kwargs = dict(batch_size=batch_size, num_workers=num_workers,\n","                     pin_memory=True, persistent_workers=(num_workers > 0))\n","\n","train_loader = DataLoader(train_ds, shuffle=True,  **loader_kwargs)\n","val_loader   = DataLoader(val_ds,   shuffle=False, **loader_kwargs)\n","test_loader  = DataLoader(test_ds,  shuffle=False, **loader_kwargs)\n","\n","# 5) Sanity check\n","print(\"Classes (alphabetical order):\", base_ds.classes)  # label mapping in .class_to_idx\n","print(\"class_to_idx:\", base_ds.class_to_idx)\n","print(f\"Train size: {len(train_ds)}, Val size: {len(val_ds)}, Test size: {len(test_ds)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lK6Bpbv5iNFF","executionInfo":{"status":"ok","timestamp":1759720848735,"user_tz":-630,"elapsed":3716,"user":{"displayName":"Sai Akshay Suresh","userId":"07578768375236954523"}},"outputId":"29175135-a184-45e9-9adf-b5beb4a02f3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Classes (alphabetical order): ['AbdomenCT', 'BreastMRI', 'ChestCT', 'ChestXR', 'HandXR', 'HeadCT']\n","class_to_idx: {'AbdomenCT': 0, 'BreastMRI': 1, 'ChestCT': 2, 'ChestXR': 3, 'HandXR': 4, 'HeadCT': 5}\n","Train size: 2250, Val size: 300, Test size: 450\n"]}]},{"cell_type":"markdown","source":["7) Let us start modelling for the source dataset (main) with ResNet-50v1 and save the checkpoints."],"metadata":{"id":"PNMc4fatiVZO"}},{"cell_type":"code","source":["# ─── 0) Mount & Imports ─────────────────────────────────────────────────────\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os, random, numpy as np\n","import torch, torch.nn as nn, torch.backends.cudnn as cudnn\n","import pandas as pd, seaborn as sns, matplotlib.pyplot as plt\n","\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader, Subset\n","from torch.optim import SGD, Adam, RMSprop, Adagrad, AdamW\n","import torch.optim.lr_scheduler as lr_scheduler\n","\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score,\n","    f1_score, roc_auc_score, mean_squared_error, confusion_matrix\n",")\n","\n","# NOTE: assumes ResNet50V1 class is already defined above in this notebook.\n","\n","# ─── 1) Determinism ─────────────────────────────────────────────────────────\n","SEED = 1906525\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","cudnn.deterministic = True   # deterministic conv algorithms\n","cudnn.benchmark = False      # avoid non-deterministic autotuner\n","\n","# ─── 2) Paths & Hyperparams ─────────────────────────────────────────────────\n","SRC_DIR = '/content/drive/MyDrive/Research Project 2025/Final Data/Preprocessed/Third Set/Source/Step 1 - Moved, Final Source Data'\n","\n","CKPT_DIR    = '/content/drive/MyDrive/Research Project 2025/Results/Main/ResNet-50/Source Training/Checkpoints'\n","CM_DIR      = '/content/drive/MyDrive/Research Project 2025/Results/Main/ResNet-50/Source Training/Confusion Matrices'\n","METRICS_DIR = '/content/drive/MyDrive/Research Project 2025/Results/Main/ResNet-50/Source Training/Performance Metrics'\n","os.makedirs(CKPT_DIR, exist_ok=True)\n","os.makedirs(CM_DIR, exist_ok=True)\n","os.makedirs(METRICS_DIR, exist_ok=True)\n","\n","MEAN = [0.2800, 0.2800, 0.2800]\n","STD  = [0.3013, 0.3013, 0.3013]\n","\n","train_tf = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(8),\n","    transforms.ToTensor(),\n","    transforms.Normalize(MEAN, STD),\n","])\n","val_tf = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(MEAN, STD),\n","])\n","\n","OPTIMIZERS  = [SGD, Adam, RMSprop, Adagrad, AdamW]\n","BATCH_SIZE  = 32\n","EPOCHS_LIST = [5, 10, 20, 40, 80]\n","LR          = 1e-3\n","DEVICE      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# ─── 3) Prepare DataLoaders (deterministic split, per-split transforms) ─────\n","base_ds = ImageFolder(SRC_DIR, transform=None)  # labels inferred by folder names\n","\n","n_total = len(base_ds)\n","n_train = int(0.75 * n_total)\n","n_val   = int(0.10 * n_total)\n","n_test  = n_total - n_train - n_val\n","\n","g = torch.Generator().manual_seed(SEED)\n","perm = torch.randperm(n_total, generator=g)\n","train_idx = perm[:n_train]\n","val_idx   = perm[n_train:n_train+n_val]\n","test_idx  = perm[n_train+n_val:]\n","\n","train_full = ImageFolder(SRC_DIR, transform=train_tf)\n","val_full   = ImageFolder(SRC_DIR, transform=val_tf)\n","test_full  = ImageFolder(SRC_DIR, transform=val_tf)\n","\n","train_ds = Subset(train_full, train_idx)\n","val_ds   = Subset(val_full,   val_idx)\n","test_ds  = Subset(test_full,  test_idx)\n","\n","loader_kwargs = dict(batch_size=BATCH_SIZE, num_workers=4, pin_memory=True)\n","train_loader = DataLoader(train_ds, shuffle=True,  **loader_kwargs)\n","val_loader   = DataLoader(val_ds,   shuffle=False, **loader_kwargs)\n","test_loader  = DataLoader(test_ds,  shuffle=False, **loader_kwargs)\n","\n","print(\"Classes:\", base_ds.classes)\n","print(\"class_to_idx:\", base_ds.class_to_idx)\n","\n","# ─── 4) Metrics / Eval helper ───────────────────────────────────────────────\n","def evaluate_split(model, loader, criterion=None, plot_cm=False, cm_name=None):\n","    model.eval()\n","    all_preds, all_labels, all_probs = [], [], []\n","    total_loss, total_samples = 0.0, 0\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            logits = model(x)\n","            if criterion is not None:\n","                total_loss += criterion(logits, y).item() * x.size(0)\n","            probs = torch.softmax(logits, dim=1).cpu().numpy()\n","            preds = logits.argmax(1).cpu().numpy()\n","            all_probs.extend(probs)\n","            all_preds.extend(preds)\n","            all_labels.extend(y.cpu().numpy())\n","            total_samples += x.size(0)\n","\n","    acc = accuracy_score(all_labels, all_preds)\n","    prec = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n","    rec  = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n","    f1   = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n","    try:\n","        auc = roc_auc_score(all_labels, np.array(all_probs), multi_class='ovo')\n","    except Exception:\n","        auc = float('nan')\n","    mse = mean_squared_error(all_labels, all_preds)\n","\n","    cm = confusion_matrix(all_labels, all_preds, labels=list(range(len(loader.dataset.dataset.classes))))\n","    total = cm.sum()\n","    specs = []\n","    for i in range(cm.shape[0]):\n","        tp = cm[i, i]\n","        fn = cm[i, :].sum() - tp\n","        fp = cm[:, i].sum() - tp\n","        tn = total - tp - fp - fn\n","        specs.append(tn / (tn + fp) if (tn + fp) > 0 else 0.0)\n","    spec = float(np.mean(specs))\n","\n","    if plot_cm and cm_name:\n","        plt.figure(figsize=(8, 6))\n","        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                    xticklabels=loader.dataset.dataset.classes,\n","                    yticklabels=loader.dataset.dataset.classes)\n","        plt.xlabel('Predicted'); plt.ylabel('Actual')\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(CM_DIR, cm_name))\n","        plt.close()\n","\n","    loss = (total_loss / total_samples) if criterion is not None else None\n","    return acc, prec, rec, spec, f1, auc, mse, loss\n","\n","# ─── 5) Training & Logging ─────────────────────────────────────────────────\n","master = []\n","\n","for opt_cls in OPTIMIZERS:\n","    for num_epochs in EPOCHS_LIST:\n","        run_name = f\"{opt_cls.__name__}_ep{num_epochs}\"\n","        print(f\"\\n▶ Run: {run_name}\")\n","\n","        # ↓↓↓ ONLY CHANGE: swap EfficientNetB0 → ResNet50V1 (already defined above)\n","        model = ResNet50V1(num_classes=len(base_ds.classes)).to(DEVICE)\n","\n","        criterion = nn.CrossEntropyLoss()\n","        optimizer = opt_cls(model.parameters(), lr=LR)\n","        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n","\n","        # gradient norm (before & after)\n","        def get_grad_norm():\n","            model.eval(); model.zero_grad()\n","            x, y = next(iter(train_loader))\n","            x, y = x.to(DEVICE), y.to(DEVICE)\n","            loss = criterion(model(x), y)\n","            loss.backward()\n","            total = 0.0\n","            for p in model.parameters():\n","                if p.grad is not None:\n","                    g = p.grad.detach()\n","                    total += float(torch.norm(g)**2)\n","            return total**0.5\n","\n","        grad_before = get_grad_norm()\n","\n","        for epoch in range(1, num_epochs + 1):\n","            model.train()\n","            for x, y in train_loader:\n","                x, y = x.to(DEVICE), y.to(DEVICE)\n","                optimizer.zero_grad()\n","                loss = criterion(model(x), y)\n","                loss.backward()\n","                optimizer.step()\n","\n","            # validation & LR schedule\n","            _, _, _, _, _, _, _, val_loss = evaluate_split(model, val_loader, criterion)\n","            scheduler.step(val_loss)\n","\n","            # save CM only when the run itself is 40 epochs, and exactly at epoch 40\n","            if num_epochs == 40 and epoch == 40:\n","                _ = evaluate_split(\n","                    model, test_loader, plot_cm=True, cm_name=f\"{opt_cls.__name__}_ep40.png\"\n","                )\n","\n","        # final metrics on train/val/test\n","        train_acc, train_prec, train_rec, train_spec, train_f1, train_auc, train_mse, _ = evaluate_split(model, train_loader)\n","        val_acc,   val_prec,   val_rec,   val_spec,   val_f1,   val_auc,   val_mse,   _ = evaluate_split(model, val_loader)\n","        test_acc,  test_prec,  test_rec,  test_spec,  test_f1,  test_auc,  test_mse,  _ = evaluate_split(model, test_loader)\n","        grad_after = get_grad_norm()\n","\n","        print(f\"Completed {run_name} → Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n","\n","        # save checkpoint\n","        torch.save(model.state_dict(), os.path.join(CKPT_DIR, f\"{opt_cls.__name__}_ep{num_epochs}.pth\"))\n","\n","        # log row (same columns; only the 'Model' value differs)\n","        master.append({\n","            'Model': 'ResNet50V1',\n","            'Optimizer': opt_cls.__name__, 'Epochs': num_epochs,\n","            'train_acc': train_acc, 'val_acc': val_acc, 'test_acc': test_acc,\n","            'train_mse': train_mse, 'val_mse': val_mse, 'test_mse': test_mse,\n","            'precision': test_prec, 'sensitivity': test_rec,\n","            'specificity': test_spec, 'f1': test_f1, 'auc': test_auc,\n","            'grad_before': grad_before, 'grad_after': grad_after\n","        })\n","\n","# write metrics Excel\n","metrics_file = os.path.join(METRICS_DIR, 'ResNet50_MainPretrain.xlsx')\n","pd.DataFrame(master).to_excel(metrics_file, index=False)\n","print(\"Training completed. Saved checkpoints, confusion matrices, and metrics (source).\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHiKwvc5iVjn","executionInfo":{"status":"ok","timestamp":1759726611207,"user_tz":-630,"elapsed":4670892,"user":{"displayName":"Sai Akshay Suresh","userId":"07578768375236954523"}},"outputId":"da79f57c-a4a6-49de-f1de-190a77f72746"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Classes: ['AbdomenCT', 'BreastMRI', 'ChestCT', 'ChestXR', 'HandXR', 'HeadCT']\n","class_to_idx: {'AbdomenCT': 0, 'BreastMRI': 1, 'ChestCT': 2, 'ChestXR': 3, 'HandXR': 4, 'HeadCT': 5}\n","\n","▶ Run: SGD_ep5\n","Completed SGD_ep5 → Train Acc: 0.7529, Test Acc: 0.7533\n","\n","▶ Run: SGD_ep10\n","Completed SGD_ep10 → Train Acc: 0.9231, Test Acc: 0.9289\n","\n","▶ Run: SGD_ep20\n","Completed SGD_ep20 → Train Acc: 0.9827, Test Acc: 0.9867\n","\n","▶ Run: SGD_ep40\n","Completed SGD_ep40 → Train Acc: 0.9982, Test Acc: 0.9978\n","\n","▶ Run: SGD_ep80\n","Completed SGD_ep80 → Train Acc: 0.9996, Test Acc: 1.0000\n","\n","▶ Run: Adam_ep5\n","Completed Adam_ep5 → Train Acc: 1.0000, Test Acc: 1.0000\n","\n","▶ Run: Adam_ep10\n","Completed Adam_ep10 → Train Acc: 0.9996, Test Acc: 1.0000\n","\n","▶ Run: Adam_ep20\n","Completed Adam_ep20 → Train Acc: 1.0000, Test Acc: 1.0000\n","\n","▶ Run: Adam_ep40\n","Completed Adam_ep40 → Train Acc: 1.0000, Test Acc: 1.0000\n","\n","▶ Run: Adam_ep80\n","Completed Adam_ep80 → Train Acc: 1.0000, Test Acc: 1.0000\n","\n","▶ Run: RMSprop_ep5\n","Completed RMSprop_ep5 → Train Acc: 0.2222, Test Acc: 0.1822\n","\n","▶ Run: RMSprop_ep10\n","Completed RMSprop_ep10 → Train Acc: 0.9991, Test Acc: 0.9956\n","\n","▶ Run: RMSprop_ep20\n","Completed RMSprop_ep20 → Train Acc: 0.9996, Test Acc: 1.0000\n","\n","▶ Run: RMSprop_ep40\n","Completed RMSprop_ep40 → Train Acc: 1.0000, Test Acc: 0.9978\n","\n","▶ Run: RMSprop_ep80\n","Completed RMSprop_ep80 → Train Acc: 1.0000, Test Acc: 1.0000\n","\n","▶ Run: Adagrad_ep5\n","Completed Adagrad_ep5 → Train Acc: 1.0000, Test Acc: 1.0000\n","\n","▶ Run: Adagrad_ep10\n","Completed Adagrad_ep10 → Train Acc: 1.0000, Test Acc: 1.0000\n","\n","▶ Run: Adagrad_ep20\n","Completed Adagrad_ep20 → Train Acc: 1.0000, Test Acc: 1.0000\n","\n","▶ Run: Adagrad_ep40\n","Completed Adagrad_ep40 → Train Acc: 1.0000, Test Acc: 1.0000\n","\n","▶ Run: Adagrad_ep80\n","Completed Adagrad_ep80 → Train Acc: 1.0000, Test Acc: 1.0000\n","\n","▶ Run: AdamW_ep5\n","Completed AdamW_ep5 → Train Acc: 0.8191, Test Acc: 0.8444\n","\n","▶ Run: AdamW_ep10\n","Completed AdamW_ep10 → Train Acc: 0.9253, Test Acc: 0.9333\n","\n","▶ Run: AdamW_ep20\n","Completed AdamW_ep20 → Train Acc: 1.0000, Test Acc: 1.0000\n","\n","▶ Run: AdamW_ep40\n","Completed AdamW_ep40 → Train Acc: 1.0000, Test Acc: 1.0000\n","\n","▶ Run: AdamW_ep80\n","Completed AdamW_ep80 → Train Acc: 1.0000, Test Acc: 1.0000\n","Training completed. Saved checkpoints, confusion matrices, and metrics (source).\n"]}]},{"cell_type":"markdown","source":["8) Let us inspect the target (unlabelled) dataset's channels and image sizes."],"metadata":{"id":"QPrz--OnCcGX"}},{"cell_type":"code","source":["import os\n","from pathlib import Path\n","from collections import Counter\n","from PIL import Image\n","\n","TARGET_DIR = Path(\"/content/drive/MyDrive/Research Project 2025/Final Data/Preprocessed/Third Set/Target/Step 2 - Target Unlabelling (Main)/Images\")\n","\n","IMAGE_EXTS = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}\n","files = [f for f in TARGET_DIR.rglob(\"*\") if f.suffix.lower() in IMAGE_EXTS and f.is_file()]\n","\n","print(f\"Total image files: {len(files)}\")\n","\n","mode_counter = Counter()\n","size_counter = Counter()\n","dimensions = []\n","\n","for f in files:\n","    try:\n","        with Image.open(f) as img:\n","            mode = img.mode  # e.g., 'RGB', 'L', etc.\n","            width, height = img.size\n","            mode_counter[mode] += 1\n","            size_counter[(width, height)] += 1\n","            dimensions.append((width, height))\n","    except Exception as e:\n","        print(f\"Error with {f}: {e}\")\n","\n","print(\"\\nImage modes (counts):\")\n","for mode, count in mode_counter.items():\n","    print(f\"  Mode: {mode}, Count: {count}\")\n","\n","print(\"\\nUnique image dimensions (width × height) and their counts:\")\n","for (w, h), count in size_counter.most_common():\n","    print(f\"  {w}×{h}: {count} images\")\n","\n","# Function to get channels from mode\n","def channels_from_mode(mode):\n","    # As noted on StackOverflow, image.getbands() gives accurate channel count\n","    return len(Image.new(mode, (1,1)).getbands())\n","\n","print(\"\\nChannels per mode:\")\n","for mode in mode_counter:\n","    print(f\"  Mode: {mode}, Channels: {channels_from_mode(mode)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MiJFlQW7CcO9","executionInfo":{"status":"ok","timestamp":1759729513945,"user_tz":-630,"elapsed":159445,"user":{"displayName":"Sai Akshay Suresh","userId":"07578768375236954523"}},"outputId":"4573b896-dd34-4974-c2f0-4467c1b75b8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total image files: 3000\n","\n","Image modes (counts):\n","  Mode: RGB, Count: 3000\n","\n","Unique image dimensions (width × height) and their counts:\n","  224×224: 3000 images\n","\n","Channels per mode:\n","  Mode: RGB, Channels: 3\n"]}]},{"cell_type":"markdown","source":["9) Let us do normalization for the target (unlabelled) dataset."],"metadata":{"id":"lHI5GnTBCzY3"}},{"cell_type":"code","source":["import os\n","from pathlib import Path\n","from PIL import Image\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","\n","class UnlabeledImageDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = Path(root_dir)\n","        self.transform = transform\n","        self.image_paths = [p for p in self.root_dir.iterdir() if p.suffix.lower() in {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}]\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img = Image.open(self.image_paths[idx]).convert('RGB')\n","        if self.transform:\n","            img = self.transform(img)\n","        return img\n","\n","# 1. Define paths\n","root = \"/content/drive/MyDrive/Research Project 2025/Final Data/Preprocessed/Third Set/Target/Step 2 - Target Unlabelling (Main)/Images\"\n","\n","# 2. Base loader to compute pre-normalization mean & std\n","base_ds = UnlabeledImageDataset(root, transform=transforms.ToTensor())\n","base_loader = DataLoader(base_ds, batch_size=64, shuffle=False, num_workers=2)\n","\n","sum_ = torch.zeros(3)\n","sum_sq = torch.zeros(3)\n","total_pixels = 0\n","\n","for imgs in base_loader:\n","    batch_pixels = imgs.size(0) * imgs.size(2) * imgs.size(3)\n","    total_pixels += batch_pixels\n","    sum_ += imgs.sum(dim=[0, 2, 3])\n","    sum_sq += (imgs ** 2).sum(dim=[0, 2, 3])\n","\n","mean_pre = sum_ / total_pixels\n","std_pre = torch.sqrt(sum_sq / total_pixels - mean_pre**2)\n","\n","print(\"Pre-normalization mean:\", mean_pre)\n","print(\"Pre-normalization std :\", std_pre)\n","\n","# 3. Transformation including normalization\n","norm_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean_pre.tolist(), std_pre.tolist())\n","])\n","\n","# 4. Loader for post-normalization checks\n","norm_ds = UnlabeledImageDataset(root, transform=norm_transform)\n","norm_loader = DataLoader(norm_ds, batch_size=64, shuffle=False, num_workers=2)\n","\n","# 5. One-batch check\n","imgs = next(iter(norm_loader))\n","print(\"One-batch post-normalization mean:\", imgs.mean(dim=[0, 2, 3]))\n","print(\"One-batch post-normalization std :\", imgs.std(dim=[0, 2, 3]))\n","\n","# 6. Full dataset post-normalization stats\n","sum_norm = torch.zeros(3)\n","sum_norm_sq = torch.zeros(3)\n","total_pixels = 0\n","\n","for imgs in norm_loader:\n","    batch_pixels = imgs.size(0) * imgs.size(2) * imgs.size(3)\n","    total_pixels += batch_pixels\n","    sum_norm += imgs.sum(dim=[0, 2, 3])\n","    sum_norm_sq += (imgs ** 2).sum(dim=[0, 2, 3])\n","\n","mean_post = sum_norm / total_pixels\n","std_post = torch.sqrt(sum_norm_sq / total_pixels - mean_post**2)\n","\n","print(\"Post-normalization mean (whole dataset):\", mean_post)\n","print(\"Post-normalization std  (whole dataset):\", std_post)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i5yNfJ7TCzhQ","executionInfo":{"status":"ok","timestamp":1759729607947,"user_tz":-630,"elapsed":93993,"user":{"displayName":"Sai Akshay Suresh","userId":"07578768375236954523"}},"outputId":"c7e73f4e-4079-46e2-cb58-180e34daf4b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pre-normalization mean: tensor([0.3018, 0.3018, 0.3018])\n","Pre-normalization std : tensor([0.3210, 0.3210, 0.3210])\n","One-batch post-normalization mean: tensor([0.9964, 0.9964, 0.9964])\n","One-batch post-normalization std : tensor([0.8414, 0.8414, 0.8414])\n","Post-normalization mean (whole dataset): tensor([4.1521e-09, 4.1521e-09, 4.1521e-09])\n","Post-normalization std  (whole dataset): tensor([1., 1., 1.])\n"]}]},{"cell_type":"markdown","source":["10) Let us do Domain Adaptation with DANN (according to https://arxiv.org/abs/1505.07818) using ResNet-50's feature extractor."],"metadata":{"id":"K9k0uLzvC29i"}},{"cell_type":"code","source":["# DANN with ResNet-50 (v1) feature extractor — drop-in replacement for the B0 version\n","\n","import os, random, numpy as np, pandas as pd, math\n","from PIL import Image\n","from tqdm import tqdm\n","\n","import torch, torch.nn as nn, torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms, datasets\n","\n","import matplotlib.pyplot as plt, seaborn as sns\n","from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_auc_score\n","\n","# ─── Reproducibility ──────────────────────────────────────\n","SEED = 1906525\n","os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","random.seed(SEED); np.random.seed(SEED)\n","torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# ─── Paths ──────\n","SRC_DIR = \"/content/drive/MyDrive/Research Project 2025/Final Data/Preprocessed/Third Set/Source/Step 1 - Moved, Final Source Data\"\n","CKPT_DIR = \"/content/drive/MyDrive/Research Project 2025/Results/Main/ResNet-50/Domain Adaptation/Source Checkpoints\"\n","TGT_IMG_ROOT = \"/content/drive/MyDrive/Research Project 2025/Final Data/Preprocessed/Third Set/Target/Step 2 - Target Unlabelling (Main)/Images\"\n","TGT_CSV = \"/content/drive/MyDrive/Research Project 2025/Final Data/Preprocessed/Third Set/Target/Step 2 - Target Unlabelling (Main)/Target Labels.csv\"\n","\n","CONF_DIR = \"/content/drive/MyDrive/Research Project 2025/Results/Main/ResNet-50/Domain Adaptation/Confusion Matrices\"\n","METRICS_DIR = \"/content/drive/MyDrive/Research Project 2025/Results/Main/ResNet-50/Domain Adaptation/Performance Metrics\"\n","os.makedirs(CONF_DIR, exist_ok=True); os.makedirs(METRICS_DIR, exist_ok=True)\n","\n","# ─── Normalization (per-branch) ──────────────────────────\n","mean_src = [0.2800, 0.2800, 0.2800]; std_src  = [0.3013, 0.3013, 0.3013]\n","mean_tgt = [0.3018, 0.3018, 0.3018]; std_tgt  = [0.3210, 0.3210, 0.3210]\n","\n","tx_src = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean_src, std_src)])\n","tx_tgt = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean_tgt, std_tgt)])\n","\n","# ─── Import / define ResNet-50 backbone ────────────────────────────────────\n","# Assumes ResNet50V1 class is defined in an above cell and exposes forward_features() → (B, 2048)\n","\n","class ResNet50_FE(nn.Module):\n","    \"\"\"Thin wrapper to expose pooled 2048-d features for DANN.\"\"\"\n","    def __init__(self, net):\n","        super().__init__()\n","        self.net = net\n","    def forward(self, x):\n","        return self.net.forward_features(x)  # (B, 2048)\n","\n","def load_resnet_features(ckpt_path, num_classes):\n","    # Instantiate ResNet-50 (v1) and load weights, dropping classifier 'fc.*'\n","    fe_full = ResNet50V1(num_classes=num_classes)\n","    sd = torch.load(ckpt_path, map_location='cpu')\n","\n","    # Drop head weights if present so only feature extractor loads\n","    for k in list(sd.keys()):\n","        if k.startswith('fc.'):\n","            sd.pop(k, None)\n","    missing, unexpected = fe_full.load_state_dict(sd, strict=False)\n","    print(f\"[load_resnet_features] missing={len(missing)} unexpected={len(unexpected)}\")\n","    return ResNet50_FE(fe_full)\n","\n","# ─── GRL (λ scales reversed gradient; λ is NOT multiplied on loss) ─────────\n","from torch.autograd import Function\n","class GradReverse(Function):\n","    @staticmethod\n","    def forward(ctx, x, lambd):\n","        ctx.lambd = lambd\n","        return x.view_as(x)\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        return grad_output.neg() * ctx.lambd, None\n","def grad_reverse(x, lambd=1.0): return GradReverse.apply(x, lambd)\n","\n","# ─── DANN head (ResNet-50 features → bottleneck → task/domain heads) ──────\n","class DANN_ResNet(nn.Module):\n","    def __init__(self, features, num_classes, bottleneck_dim=256, p_drop=0.2):\n","        super().__init__()\n","        self.features = features           # returns (B, 2048)\n","        self.bottleneck = nn.Sequential(\n","            nn.Linear(2048, bottleneck_dim),\n","            nn.BatchNorm1d(bottleneck_dim),\n","            nn.ReLU(True),\n","        )\n","        self.cls_head = nn.Sequential(\n","            nn.Dropout(p_drop),\n","            nn.Linear(bottleneck_dim, num_classes)\n","        )\n","        self.dom_head = nn.Sequential(\n","            nn.Linear(bottleneck_dim, 100), nn.ReLU(True),\n","            nn.Linear(100, 2)\n","        )\n","    def forward(self, x, lambda_=0.0):\n","        f = self.features(x)               # (B, 2048)\n","        z = self.bottleneck(f)             # (B, 256)\n","        y_logits = self.cls_head(z)        # class logits\n","        z_rev = grad_reverse(z, lambda_)   # GRL\n","        d_logits = self.dom_head(z_rev)    # domain logits (2-class)\n","        return y_logits, d_logits\n","\n","# ─── Datasets & loaders ───────────────────────────────────────────────────\n","# Source labeled\n","src_ds = datasets.ImageFolder(SRC_DIR, transform=tx_src)\n","CLASS_NAMES = src_ds.classes\n","CLASS_TO_IDX = {c:i for i,c in enumerate(CLASS_NAMES)}\n","N_CLASSES = len(CLASS_NAMES)\n","\n","def src_loader(bs=32, shuffle=True, num_workers=2):\n","    return DataLoader(src_ds, batch_size=bs, shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n","\n","# Target flat folder + CSV with true labels (for evaluation only)\n","class TargetFlatCSV(Dataset):\n","    def __init__(self, root, csv_path, transform):\n","        self.root = root; self.transform = transform\n","        df = pd.read_csv(csv_path)\n","        self.names = df.iloc[:,0].astype(str).tolist()\n","        self.cls_names = df.iloc[:,1].astype(str).tolist()\n","        self.cls_idx = [CLASS_TO_IDX[c] for c in self.cls_names]\n","    def __len__(self): return len(self.names)\n","    def __getitem__(self, i):\n","        fp = os.path.join(self.root, self.names[i])\n","        img = Image.open(fp).convert(\"RGB\")\n","        return self.transform(img), self.cls_idx[i], self.names[i]\n","\n","tgt_ds = TargetFlatCSV(TGT_IMG_ROOT, TGT_CSV, tx_tgt)\n","\n","def tgt_loader(bs=32, shuffle=True, num_workers=2):\n","    return DataLoader(tgt_ds, batch_size=bs, shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n","\n","# ─── Metrics helpers ──────────────────────────────────────────\n","def save_confusion_matrix(y_true, y_pred, class_names, save_path):\n","    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n","    plt.figure(figsize=(10,8))\n","    ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                     xticklabels=class_names, yticklabels=class_names,\n","                     cbar=False, linewidths=.5)\n","    ax.set_xlabel('Predicted'); ax.set_ylabel('Actual'); ax.set_title('Confusion Matrix (Target)')\n","    plt.tight_layout(); plt.savefig(save_path, dpi=220); plt.close()\n","    return cm\n","\n","def specificity_from_cm(cm):\n","    spec = []\n","    for k in range(cm.shape[0]):\n","        TP = cm[k,k]\n","        FP = cm[:,k].sum() - TP\n","        FN = cm[k,:].sum() - TP\n","        TN = cm.sum() - (TP+FP+FN)\n","        spec.append( TN / (TN + FP + 1e-12) )\n","    return np.array(spec)\n","\n","def macro_auc(y_true, y_proba, n_classes):\n","    y_true_oh = np.eye(n_classes)[np.asarray(y_true)]\n","    return roc_auc_score(y_true_oh, y_proba, average=\"macro\", multi_class=\"ovr\")\n","\n","# ─── One run: (checkpoint, λ) train + evaluate ────────────────────────────\n","def dann_train_eval(ckpt_path, ckpt_name, lambda_val, epochs=10, bs=32, lr=1e-4):\n","    # loaders\n","    Ls = src_loader(bs=bs, shuffle=True)\n","    Lt = tgt_loader(bs=bs, shuffle=True)\n","\n","    # backbone + heads  (ResNet-50 now)\n","    feats = load_resnet_features(ckpt_path, N_CLASSES)\n","    model = DANN_ResNet(feats, N_CLASSES).to(device)\n","\n","    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n","    ce = nn.CrossEntropyLoss()\n","\n","    model.train()\n","    it_tgt = iter(Lt)\n","    for ep in range(epochs):\n","        for x_s, y_s in Ls:\n","            x_s, y_s = x_s.to(device), y_s.to(device)\n","            try:\n","                x_t, _, _ = next(it_tgt)\n","            except StopIteration:\n","                it_tgt = iter(Lt)\n","                x_t, _, _ = next(it_tgt)\n","            x_t = x_t.to(device)\n","\n","            # 1) Task loss on labeled source (no GRL)\n","            y_logits_s, _ = model(x_s, lambda_=0.0)\n","            L_cls = ce(y_logits_s, y_s)\n","\n","            # 2) Domain loss on concat(source,target) with GRL(λ)\n","            x_dom = torch.cat([x_s, x_t], dim=0)\n","            _, d_logits = model(x_dom, lambda_=lambda_val)   # GRL scales gradients only\n","            d_labels = torch.cat([\n","                torch.zeros(x_s.size(0), dtype=torch.long),\n","                torch.ones(x_t.size(0), dtype=torch.long)\n","            ], dim=0).to(device)\n","            L_dom = ce(d_logits, d_labels)\n","\n","            loss = L_cls + L_dom\n","            opt.zero_grad(); loss.backward(); opt.step()\n","\n","    # ── Evaluate on ALL target images (order from dataset)\n","    model.eval()\n","    all_true, all_pred, all_prob = [], [], []\n","    with torch.no_grad():\n","        for xb, yb, _names in DataLoader(tgt_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=True):\n","            xb = xb.to(device)\n","            y_logits, _ = model(xb, lambda_=0.0)\n","            probs = torch.softmax(y_logits, dim=1)\n","            pred = probs.argmax(dim=1)\n","            all_true.extend(yb.tolist())\n","            all_pred.extend(pred.cpu().tolist())\n","            all_prob.append(probs.cpu().numpy())\n","    all_prob = np.concatenate(all_prob, axis=0)\n","\n","    # ── Metrics\n","    correct = int(np.sum(np.array(all_true)==np.array(all_pred)))\n","    total = len(all_true)\n","    acc = correct / total\n","    miss = 1.0 - acc\n","\n","    prec, rec, f1, _ = precision_recall_fscore_support(\n","        all_true, all_pred, labels=list(range(N_CLASSES)),\n","        average='macro', zero_division=0\n","    )\n","    cm = save_confusion_matrix(\n","        all_true, all_pred, CLASS_NAMES,\n","        os.path.join(CONF_DIR, f\"{ckpt_name}_{lambda_val}.png\")\n","    )\n","    spec_macro = specificity_from_cm(cm).mean()\n","\n","    try:\n","        auc_macro = macro_auc(all_true, all_prob, N_CLASSES)\n","    except Exception:\n","        auc_macro = float('nan')\n","\n","    row = {\n","        \"Checkpoint\": ckpt_name,\n","        \"GAN Type\": \"DANN\",\n","        \"DA Hyperparameter\": \"lambda\",\n","        \"DA Hyperparameter Value\": lambda_val,\n","        \"Correctly Identified Images\": correct,\n","        \"Incorrectly Identified Images\": total - correct,\n","        \"Image Classification Accuracy\": acc,\n","        \"Image Miss Rate\": miss,\n","        \"Precision (macro)\": prec,\n","        \"Sensitivity/Recall (macro)\": rec,\n","        \"Specificity (macro)\": spec_macro,\n","        \"F1-Score (macro)\": f1,\n","        \"AUC-ROC (macro OvR)\": auc_macro\n","    }\n","    return row\n","\n","# ─── Grid: 5 checkpoints × 5 λ values ─────────────────────────────────────\n","lambda_vals = [0.01, 0.05, 0.1, 0.5, 1.0]\n","ckpt_files = [f for f in os.listdir(CKPT_DIR) if f.endswith(\".pth\")]\n","results = []\n","\n","for fname in tqdm(sorted(ckpt_files), desc=\"Checkpoints x lambdas (ResNet50-DANN)\"):\n","    ckpt_path = os.path.join(CKPT_DIR, fname)\n","    ckpt_name = os.path.splitext(fname)[0].replace(\" \", \"\").replace(\"-\", \"\").replace(\"__\", \"_\")\n","    for lam in lambda_vals:\n","        row = dann_train_eval(ckpt_path, ckpt_name, lam, epochs=10, bs=32, lr=1e-4)\n","        results.append(row)\n","\n","# ─── Save Excel ───────────────────────────────\n","df = pd.DataFrame(results)\n","\n","ordered = (\n","    [\"Checkpoint\",\"GAN Type\",\"DA Hyperparameter\",\"DA Hyperparameter Value\"] +\n","    [c for c in df.columns if c not in [\"Checkpoint\",\"GAN Type\",\"DA Hyperparameter\",\"DA Hyperparameter Value\"]]\n",")\n","df = df[ordered]\n","\n","save_xlsx = os.path.join(METRICS_DIR, \"ResNet50_Main(DANN).xlsx\")\n","df.to_excel(save_xlsx, index=False)\n","print(f\"✅ Saved metrics to: {save_xlsx}\")\n","print(f\"✅ Confusion matrices in: {CONF_DIR}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v42dcsvjC3WR","executionInfo":{"status":"ok","timestamp":1759736504926,"user_tz":-630,"elapsed":4502825,"user":{"displayName":"Sai Akshay Suresh","userId":"07578768375236954523"}},"outputId":"4e76b6ea-8fdc-44ae-9eaf-9ed888805e92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\rCheckpoints x lambdas (ResNet50-DANN):   0%|          | 0/5 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n"]},{"output_type":"stream","name":"stderr","text":["\rCheckpoints x lambdas (ResNet50-DANN):  20%|██        | 1/5 [30:23<2:01:35, 1823.95s/it]"]},{"output_type":"stream","name":"stdout","text":["[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n"]},{"output_type":"stream","name":"stderr","text":["\rCheckpoints x lambdas (ResNet50-DANN):  40%|████      | 2/5 [41:32<57:12, 1144.07s/it]  "]},{"output_type":"stream","name":"stdout","text":["[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n"]},{"output_type":"stream","name":"stderr","text":["\rCheckpoints x lambdas (ResNet50-DANN):  60%|██████    | 3/5 [52:40<30:53, 926.94s/it] "]},{"output_type":"stream","name":"stdout","text":["[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n"]},{"output_type":"stream","name":"stderr","text":["\rCheckpoints x lambdas (ResNet50-DANN):  80%|████████  | 4/5 [1:03:48<13:44, 824.64s/it]"]},{"output_type":"stream","name":"stdout","text":["[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n"]},{"output_type":"stream","name":"stderr","text":["Checkpoints x lambdas (ResNet50-DANN): 100%|██████████| 5/5 [1:15:02<00:00, 900.46s/it]\n"]},{"output_type":"stream","name":"stdout","text":["✅ Saved metrics to: /content/drive/MyDrive/Research Project 2025/Results/Main/ResNet-50/Domain Adaptation/Performance Metrics/ResNet50_Main(DANN).xlsx\n","✅ Confusion matrices in: /content/drive/MyDrive/Research Project 2025/Results/Main/ResNet-50/Domain Adaptation/Confusion Matrices\n"]}]},{"cell_type":"markdown","source":["11) Let us do Domain Adaptation with CDAN+E (according to https://arxiv.org/abs/1705.10667) using ResNet-50's feature extractor."],"metadata":{"id":"kMfIuYj5JMlT"}},{"cell_type":"code","source":["# =========================\n","# CDAN+E with ResNet-50 (v1) feature extractor\n","# Faithful to our DANN setup (paths/metrics/optim/epochs/λ-grid)\n","# Multilinear conditioning + Entropy conditioning per CDAN (NeurIPS'18)\n","# =========================\n","import os, random, numpy as np, pandas as pd, math\n","from PIL import Image\n","from tqdm import tqdm\n","\n","import torch, torch.nn as nn, torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms, datasets\n","\n","import matplotlib.pyplot as plt, seaborn as sns\n","from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_auc_score\n","\n","# ─── Reproducibility ──────────────────────────────────────\n","SEED = 1906525\n","os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","random.seed(SEED); np.random.seed(SEED)\n","torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# ─── Paths ───────────────────────\n","SRC_DIR = \"/content/drive/MyDrive/Research Project 2025/Final Data/Preprocessed/Third Set/Source/Step 1 - Moved, Final Source Data\"\n","CKPT_DIR = \"/content/drive/MyDrive/Research Project 2025/Results/Main/ResNet-50/Domain Adaptation/Source Checkpoints\"\n","TGT_IMG_ROOT = \"/content/drive/MyDrive/Research Project 2025/Final Data/Preprocessed/Third Set/Target/Step 2 - Target Unlabelling (Main)/Images\"\n","TGT_CSV = \"/content/drive/MyDrive/Research Project 2025/Final Data/Preprocessed/Third Set/Target/Step 2 - Target Unlabelling (Main)/Target Labels.csv\"\n","\n","CONF_DIR = \"/content/drive/MyDrive/Research Project 2025/Results/Main/ResNet-50/Domain Adaptation/CDAN+E/Confusion Matrices\"\n","METRICS_DIR = \"/content/drive/MyDrive/Research Project 2025/Results/Main/ResNet-50/Domain Adaptation/CDAN+E/Performance Metrics\"\n","os.makedirs(CONF_DIR, exist_ok=True); os.makedirs(METRICS_DIR, exist_ok=True)\n","\n","# ─── Normalization ────────────────────\n","mean_src = [0.2800, 0.2800, 0.2800]; std_src  = [0.3013, 0.3013, 0.3013]\n","mean_tgt = [0.3018, 0.3018, 0.3018]; std_tgt  = [0.3210, 0.3210, 0.3210]\n","\n","tx_src = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean_src, std_src)])\n","tx_tgt = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean_tgt, std_tgt)])\n","\n","# ─── Import / define ResNet-50 backbone (assumes ResNet50V1 above) ────────\n","class ResNet50_FE(nn.Module):\n","    \"\"\"Thin wrapper to expose pooled 2048-d features for DA.\"\"\"\n","    def __init__(self, net):\n","        super().__init__()\n","        self.net = net\n","    def forward(self, x):\n","        return self.net.forward_features(x)  # (B, 2048)\n","\n","def load_resnet_features(ckpt_path, num_classes):\n","    # Instantiate ResNet-50 (v1) and load weights, dropping classifier 'fc.*'\n","    fe_full = ResNet50V1(num_classes=num_classes)\n","    sd = torch.load(ckpt_path, map_location='cpu')\n","    for k in list(sd.keys()):\n","        if k.startswith('fc.'):\n","            sd.pop(k, None)\n","    missing, unexpected = fe_full.load_state_dict(sd, strict=False)\n","    print(f\"[load_resnet_features] missing={len(missing)} unexpected={len(unexpected)}\")\n","    return ResNet50_FE(fe_full)\n","\n","# ─── GRL (λ scales reversed gradients) ─────────────────────────────────────\n","from torch.autograd import Function\n","class GradReverse(Function):\n","    @staticmethod\n","    def forward(ctx, x, lambd):\n","        ctx.lambd = lambd\n","        return x.view_as(x)\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        return grad_output.neg() * ctx.lambd, None\n","def grad_reverse(x, lambd=1.0): return GradReverse.apply(x, lambd)\n","\n","# ─── CDAN+E head (ResNet-50 features → bottleneck → task head; domain head on f⊗g) ──\n","class CDAN_ResNet(nn.Module):\n","    \"\"\"\n","    Multilinear conditioning (outer product) per CDAN Eq.(4)/(9); entropy conditioning in loss.\n","    Bottleneck keeps dims manageable (256) ⇒ f⊗g has 256*C (here 1536 < 4096).\n","    \"\"\"\n","    def __init__(self, features, num_classes, bottleneck_dim=256, p_drop=0.2):\n","        super().__init__()\n","        self.features = features           # (B, 2048)\n","        self.bottleneck = nn.Sequential(\n","            nn.Linear(2048, bottleneck_dim),\n","            nn.BatchNorm1d(bottleneck_dim),\n","            nn.ReLU(True),\n","        )\n","        self.cls_head = nn.Sequential(\n","            nn.Dropout(p_drop),\n","            nn.Linear(bottleneck_dim, num_classes)\n","        )\n","        # Domain head consumes flattened outer-product f⊗g (B, bottleneck_dim * num_classes)\n","        dom_in = bottleneck_dim * num_classes\n","        self.dom_head = nn.Sequential(\n","            nn.Linear(dom_in, 1024), nn.ReLU(True),\n","            nn.Linear(1024, 2)\n","        )\n","\n","    def forward(self, x, lambda_=0.0):\n","        f = self.features(x)               # (B, 2048)\n","        z = self.bottleneck(f)             # (B, 256)\n","        y_logits = self.cls_head(z)        # class logits (B, C)\n","        # Softmax for g (probabilities) used by CDAN conditioning\n","        g = torch.softmax(y_logits, dim=1) # (B, C)\n","\n","        # Multilinear conditioning: outer product z ⊗ g  → (B, 256, C) → flatten → (B, 256*C)\n","        outer = torch.bmm(z.unsqueeze(2), g.unsqueeze(1)).view(z.size(0), -1)\n","\n","        # GRL on conditioned representation\n","        outer_rev = grad_reverse(outer, lambda_)\n","        d_logits = self.dom_head(outer_rev)    # (B, 2)\n","        return y_logits, d_logits, g  # return g for entropy weighting\n","\n","# ─── Datasets & loaders ───────────────────────────────────────────────────\n","# Source labeled\n","src_ds = datasets.ImageFolder(SRC_DIR, transform=tx_src)\n","CLASS_NAMES = src_ds.classes\n","CLASS_TO_IDX = {c:i for i,c in enumerate(CLASS_NAMES)}\n","N_CLASSES = len(CLASS_NAMES)\n","\n","def src_loader(bs=32, shuffle=True, num_workers=2):\n","    return DataLoader(src_ds, batch_size=bs, shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n","\n","# Target flat folder + CSV with true labels (for evaluation)\n","class TargetFlatCSV(Dataset):\n","    def __init__(self, root, csv_path, transform):\n","        self.root = root; self.transform = transform\n","        df = pd.read_csv(csv_path)\n","        self.names = df.iloc[:,0].astype(str).tolist()\n","        self.cls_names = df.iloc[:,1].astype(str).tolist()\n","        self.cls_idx = [CLASS_TO_IDX[c] for c in self.cls_names]\n","    def __len__(self): return len(self.names)\n","    def __getitem__(self, i):\n","        fp = os.path.join(self.root, self.names[i])\n","        img = Image.open(fp).convert(\"RGB\")\n","        return self.transform(img), self.cls_idx[i], self.names[i]\n","\n","tgt_ds = TargetFlatCSV(TGT_IMG_ROOT, TGT_CSV, tx_tgt)\n","\n","def tgt_loader(bs=32, shuffle=True, num_workers=2):\n","    return DataLoader(tgt_ds, batch_size=bs, shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n","\n","# ─── Metrics helpers ────────────────────────────────────\n","def save_confusion_matrix(y_true, y_pred, class_names, save_path):\n","    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n","    plt.figure(figsize=(10,8))\n","    ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                     xticklabels=class_names, yticklabels=class_names,\n","                     cbar=False, linewidths=.5)\n","    ax.set_xlabel('Predicted'); ax.set_ylabel('Actual'); ax.set_title('Confusion Matrix (Target)')\n","    plt.tight_layout(); plt.savefig(save_path, dpi=220); plt.close()\n","    return cm\n","\n","def specificity_from_cm(cm):\n","    spec = []\n","    for k in range(cm.shape[0]):\n","        TP = cm[k,k]\n","        FP = cm[:,k].sum() - TP\n","        FN = cm[k,:].sum() - TP\n","        TN = cm.sum() - (TP+FP+FN)\n","        spec.append( TN / (TN + FP + 1e-12) )\n","    return np.array(spec)\n","\n","def macro_auc(y_true, y_proba, n_classes):\n","    y_true_oh = np.eye(n_classes)[np.asarray(y_true)]\n","    return roc_auc_score(y_true_oh, y_proba, average=\"macro\", multi_class=\"ovr\")\n","\n","# ─── One run: (checkpoint, λ) train + evaluate (CDAN+E) ───────────────────\n","def cdan_train_eval(ckpt_path, ckpt_name, lambda_val, epochs=10, bs=32, lr=1e-4):\n","    # loaders\n","    Ls = src_loader(bs=bs, shuffle=True)\n","    Lt = tgt_loader(bs=bs, shuffle=True)\n","\n","    # backbone + heads  (ResNet-50 now)\n","    feats = load_resnet_features(ckpt_path, N_CLASSES)\n","    model = CDAN_ResNet(feats, N_CLASSES).to(device)\n","\n","    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n","    ce_cls = nn.CrossEntropyLoss()\n","    ce_dom = nn.CrossEntropyLoss(reduction='none')  # per-sample for entropy weights\n","\n","    model.train()\n","    it_tgt = iter(Lt)\n","    for ep in range(epochs):\n","        for x_s, y_s in Ls:\n","            x_s, y_s = x_s.to(device), y_s.to(device)\n","            try:\n","                x_t, _, _ = next(it_tgt)\n","            except StopIteration:\n","                it_tgt = iter(Lt)\n","                x_t, _, _ = next(it_tgt)\n","            x_t = x_t.to(device)\n","\n","            # 1) Task loss on labeled source (no GRL)\n","            y_logits_s, d_logits_dummy, g_s = model(x_s, lambda_=0.0)\n","            L_cls = ce_cls(y_logits_s, y_s)\n","\n","            # 2) Domain loss on concat(source,target) with GRL(λ) + Entropy conditioning weights\n","            x_dom = torch.cat([x_s, x_t], dim=0)\n","            y_logits_all, d_logits, g_all = model(x_dom, lambda_=lambda_val)  # g_all used only for weights\n","\n","            # Domain labels: 0 for source, 1 for target\n","            d_labels = torch.cat([\n","                torch.zeros(x_s.size(0), dtype=torch.long),\n","                torch.ones(x_t.size(0), dtype=torch.long)\n","            ], dim=0).to(device)\n","\n","            # Entropy H(g) = -∑ g_c log g_c ; weights w = 1 + exp(-H)  (CDAN+E)\n","            g_clamped = torch.clamp(g_all, 1e-6, 1.0)\n","            H = -(g_clamped * torch.log(g_clamped)).sum(dim=1)          # (B,)\n","            w = 1.0 + torch.exp(-H)                                     # (B,)\n","            # Per-sample CE, weight and normalize by mean weight\n","            L_dom_vec = ce_dom(d_logits, d_labels)                      # (B,)\n","            L_dom = (w * L_dom_vec).sum() / (w.sum() + 1e-12)\n","\n","            loss = L_cls + L_dom\n","            opt.zero_grad(); loss.backward(); opt.step()\n","\n","    # ── Evaluate on ALL target images (order from dataset)\n","    model.eval()\n","    all_true, all_pred, all_prob = [], [], []\n","    with torch.no_grad():\n","        for xb, yb, _names in DataLoader(tgt_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=True):\n","            xb = xb.to(device)\n","            y_logits, _, _ = model(xb, lambda_=0.0)\n","            probs = torch.softmax(y_logits, dim=1)\n","            pred = probs.argmax(dim=1)\n","            all_true.extend(yb.tolist())\n","            all_pred.extend(pred.cpu().tolist())\n","            all_prob.append(probs.cpu().numpy())\n","    all_prob = np.concatenate(all_prob, axis=0)\n","\n","    # ── Metrics\n","    correct = int(np.sum(np.array(all_true)==np.array(all_pred)))\n","    total = len(all_true)\n","    acc = correct / total\n","    miss = 1.0 - acc\n","\n","    prec, rec, f1, _ = precision_recall_fscore_support(\n","        all_true, all_pred, labels=list(range(N_CLASSES)),\n","        average='macro', zero_division=0\n","    )\n","    cm = save_confusion_matrix(\n","        all_true, all_pred, CLASS_NAMES,\n","        os.path.join(CONF_DIR, f\"{ckpt_name}_{lambda_val}.png\")\n","    )\n","    spec_macro = specificity_from_cm(cm).mean()\n","\n","    try:\n","        auc_macro = macro_auc(all_true, all_prob, N_CLASSES)\n","    except Exception:\n","        auc_macro = float('nan')\n","\n","    row = {\n","        \"Checkpoint\": ckpt_name,\n","        \"GAN Type\": \"CDAN+E\",\n","        \"DA Hyperparameter\": \"lambda\",\n","        \"DA Hyperparameter Value\": lambda_val,\n","        \"Correctly Identified Images\": correct,\n","        \"Incorrectly Identified Images\": total - correct,\n","        \"Image Classification Accuracy\": acc,\n","        \"Image Miss Rate\": miss,\n","        \"Precision (macro)\": prec,\n","        \"Sensitivity/Recall (macro)\": rec,\n","        \"Specificity (macro)\": spec_macro,\n","        \"F1-Score (macro)\": f1,\n","        \"AUC-ROC (macro OvR)\": auc_macro\n","    }\n","    return row\n","\n","# ─── Grid: checkpoints × λ values ──────────────────────────────────────────\n","lambda_vals = [0.01, 0.05, 0.1, 0.5, 1.0]\n","ckpt_files = [f for f in os.listdir(CKPT_DIR) if f.endswith(\".pth\")]\n","results = []\n","\n","for fname in tqdm(sorted(ckpt_files), desc=\"Checkpoints x lambdas (ResNet50-CDAN+E)\"):\n","    ckpt_path = os.path.join(CKPT_DIR, fname)\n","    ckpt_name = os.path.splitext(fname)[0].replace(\" \", \"\").replace(\"-\", \"\").replace(\"__\", \"_\")\n","    for lam in lambda_vals:\n","        row = cdan_train_eval(ckpt_path, ckpt_name, lam, epochs=10, bs=32, lr=1e-4)\n","        results.append(row)\n","\n","# ─── Save Excel ────────────────────────────────────────────────────────────\n","df = pd.DataFrame(results)\n","ordered = (\n","    [\"Checkpoint\",\"GAN Type\",\"DA Hyperparameter\",\"DA Hyperparameter Value\"] +\n","    [c for c in df.columns if c not in [\"Checkpoint\",\"GAN Type\",\"DA Hyperparameter\",\"DA Hyperparameter Value\"]]\n",")\n","df = df[ordered]\n","\n","save_xlsx = os.path.join(METRICS_DIR, \"ResNet50_Main(CDAN).xlsx\")\n","df.to_excel(save_xlsx, index=False)\n","print(f\"✅ Saved metrics to: {save_xlsx}\")\n","print(f\"✅ Confusion matrices in: {CONF_DIR}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6WfRDd0zJM3u","executionInfo":{"status":"ok","timestamp":1761900473953,"user_tz":-630,"elapsed":4521157,"user":{"displayName":"Sai Akshay Suresh","userId":"07578768375236954523"}},"outputId":"d9d55bc3-2b26-406e-ce9d-95ce0dd67d95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\rCheckpoints x lambdas (ResNet50-CDAN+E):   0%|          | 0/5 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n"]},{"output_type":"stream","name":"stderr","text":["\rCheckpoints x lambdas (ResNet50-CDAN+E):  20%|██        | 1/5 [29:45<1:59:02, 1785.56s/it]"]},{"output_type":"stream","name":"stdout","text":["[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n"]},{"output_type":"stream","name":"stderr","text":["\rCheckpoints x lambdas (ResNet50-CDAN+E):  40%|████      | 2/5 [41:03<56:41, 1133.91s/it]  "]},{"output_type":"stream","name":"stdout","text":["[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n"]},{"output_type":"stream","name":"stderr","text":["\rCheckpoints x lambdas (ResNet50-CDAN+E):  60%|██████    | 3/5 [52:26<30:56, 928.03s/it] "]},{"output_type":"stream","name":"stdout","text":["[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n"]},{"output_type":"stream","name":"stderr","text":["\rCheckpoints x lambdas (ResNet50-CDAN+E):  80%|████████  | 4/5 [1:03:42<13:48, 828.58s/it]"]},{"output_type":"stream","name":"stdout","text":["[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n","[load_resnet_features] missing=2 unexpected=0\n"]},{"output_type":"stream","name":"stderr","text":["Checkpoints x lambdas (ResNet50-CDAN+E): 100%|██████████| 5/5 [1:15:02<00:00, 900.48s/it]\n"]},{"output_type":"stream","name":"stdout","text":["✅ Saved metrics to: /content/drive/MyDrive/Research Project 2025/Results/Main/ResNet-50/Domain Adaptation/CDAN+E/Performance Metrics/ResNet50_Main(CDAN).xlsx\n","✅ Confusion matrices in: /content/drive/MyDrive/Research Project 2025/Results/Main/ResNet-50/Domain Adaptation/CDAN+E/Confusion Matrices\n"]}]}]}